{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d14d10",
   "metadata": {},
   "source": [
    "\n",
    "# <img src=\"imagenes\\logo uem.png\" width=\"300\" height=\"600\" align=\"left \"><b>PROYECTO OPEN DATA II     -          *Universidad Europea de Madrid* \n",
    "\n",
    "   > ## <font color='blue'>Predictor de precios de venta de viviendas en Ames, Iowa, EEUU</font>  \n",
    "<div style=\" color:#000000; font-style: normal; font-family: Georgia;\">\n",
    "    Alumnos: Carlos García y Víctor Salvador "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd02131",
   "metadata": {},
   "source": [
    "<img src=\"imagenes\\ames.jpg\" width=\"1000\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba5ea1",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929e0c4",
   "metadata": {},
   "source": [
    "## 1. Importación y limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e14d1f3",
   "metadata": {},
   "source": [
    "### 1.1 Librerías importadas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d04f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings   #Control de advertencias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168cee85",
   "metadata": {},
   "source": [
    "### 1.2 Datos importados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9d33e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size is (2919, 80)\n",
      "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley',\n",
      "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
      "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
      "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
      "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
      "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
      "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
      "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
      "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
      "       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
      "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
      "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
      "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal',\n",
      "       'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('./train.csv',index_col=['Id'])\n",
    "test_ns=pd.read_csv('./test.csv',index_col=['Id'])\n",
    "SalePrice=pd.read_csv('./sample_submission.csv',names=['Id','SalePrice'],skiprows=1,index_col=['Id'])\n",
    "test=pd.concat((test_ns,SalePrice),axis=1) #distinguiremos el train y el test más adelante\n",
    "\n",
    "house=pd.concat((train,test),sort=False).reset_index(drop=True)\n",
    "print(f\"Total size is {house.shape}\")\n",
    "print(house.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e8486b",
   "metadata": {},
   "source": [
    "###  1.3 Limpieza de datos <img src=\"imagenes\\limpieza datos 3.png\" width=\"80\" height=\"100\" align=\"center \">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c94a74",
   "metadata": {},
   "source": [
    "#### Eliminación de campos demasiado vacíos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71f4c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 campos eliminados del dataset\n"
     ]
    }
   ],
   "source": [
    "h=house.dropna(thresh=len(house)*0.8,axis=1)\n",
    "print(f'{house.shape[1]-h.shape[1]} campos eliminados del dataset') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da65ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allna = (h.isnull().sum() / len(h))*100             \n",
    "allna = allna.drop(allna[allna == 0].index).sort_values()\n",
    "NA=h[allna.index.to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33692b",
   "metadata": {},
   "source": [
    "#### Relleno de valores vacíos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ead5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 18 campos categóricos con valores vacíos\n",
      "Tenemos 11 campos numéricos con valores vacíos\n"
     ]
    }
   ],
   "source": [
    "NAcat=NA.select_dtypes(include='object') #no que no es numérico\n",
    "NAnum=NA.select_dtypes(exclude='object') #lo que es numérico\n",
    "print(f'Tenemos {NAcat.shape[1]} campos categóricos con valores vacíos')\n",
    "print(f'Tenemos {NAnum.shape[1]} campos numéricos con valores vacíos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1019c80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BsmtUnfSF', 'GarageArea', 'GarageCars', 'TotalBsmtSF', 'BsmtFinSF2',\n",
       "       'BsmtFinSF1', 'BsmtHalfBath', 'BsmtFullBath', 'MasVnrArea',\n",
       "       'GarageYrBlt', 'LotFrontage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAnum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c797a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCol=[['MasVnrArea'],['BsmtFinSF2'],['BsmtFullBath'],['BsmtHalfBath'],\n",
    "      ['BsmtUnfSF'],['TotalBsmtSF'],['BsmtFinSF1'],['GarageCars'],['GarageArea']]\n",
    "\n",
    "for col in NCol:\n",
    "    h[col]= h[col].fillna(0) #Rellenamos los vacíos con 0 porque Na significa la ausencia de estas características\n",
    "#media\n",
    "h['LotFrontage']=h['LotFrontage'].fillna(h.LotFrontage.mean()) #Rellenamos los valores vacíos con la media\n",
    "h['GarageYrBlt']=h[\"GarageYrBlt\"].fillna(h.GarageYrBlt.median()) #Rellenamos los varloes vacíos con la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "140ce98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_NA(data, columns, METHOD='ffill'): #Función para rellenar columnas \n",
    "    fill_cols = columns\n",
    "    \n",
    "    for col in data[fill_cols]:\n",
    "        data[col]= data[col].fillna(method=METHOD) \n",
    "        #ffill significa 'forward fill' y propagará la última observación válida hacia adelante.\n",
    "    \n",
    "    return data\n",
    "\n",
    "ffill_cols = ['Electrical', 'SaleType', 'KitchenQual', 'Exterior1st',\n",
    "             'Exterior2nd', 'Functional', 'Utilities', 'MSZoning']\n",
    "\n",
    "\n",
    "hh=filling_NA(h, ffill_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b385f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAcols=hh.columns\n",
    "for col in NAcols:\n",
    "    if hh[col].dtype == \"object\":\n",
    "        hh[col] = hh[col].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fb8f795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass      0\n",
       "GarageYrBlt     0\n",
       "Fireplaces      0\n",
       "Functional      0\n",
       "TotRmsAbvGrd    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1498ae15",
   "metadata": {},
   "source": [
    "Ningun valor vacío en nuestro dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6febe",
   "metadata": {},
   "source": [
    "#### Agrupación de campos relacionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f37ddc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh['TotalArea'] = hh['TotalBsmtSF'] + hh['1stFlrSF'] + hh['2ndFlrSF'] + hh['GrLivArea'] +hh['GarageArea']\n",
    "\n",
    "hh['Bathrooms'] = hh['FullBath'] + hh['HalfBath']*0.5 \n",
    "\n",
    "hh['YearAverage']= (hh['YearRemodAdd']+hh['YearBuilt'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "484a3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh['PrecioVenta']=hh['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7781ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh=hh.drop(['TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageArea',\n",
    "        'FullBath','HalfBath','YearRemodAdd','YearBuilt','SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceac4c8",
   "metadata": {},
   "source": [
    "#### Eliminación de las columnas de tipo objeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b36b4",
   "metadata": {},
   "source": [
    "Por la naturaleza de los algoritmos de regresión que utilizaremos más adelante, prescindiremos de las columnas tipo object. A excepción del campo Neighborhood, debido a su relevancia ya demostrada en la parte exploratoria de este proyecto; la cual será discretizada a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1435c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh['Neighborhood']=hh['Neighborhood'].replace({'CollgCr':1,'Veenker':2,'Crawfor':3,\n",
    "                                                              'NoRidge':4,'Mitchel':5,'Somerst':6,\n",
    "                                                              'NWAmes':7,'OldTown':8,'BrkSide':9,\n",
    "                                                              'Sawyer':10,'NridgHt':11,'NAmes':12,\n",
    "                                                              'SawyerW':13,'IDOTRR':14,'MeadowV':15,\n",
    "                                                              'Edwards':16,'Timber':17,'Gilbert':18,\n",
    "                                                              'StoneBr':19,'ClearCr':20,'NPkVill':21,\n",
    "                                                              'Blmngtn':22,'BrDale':23,'SWISU':24,\n",
    "                                                              'Blueste':25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92726bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.Neighborhood.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09529906",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_train=hh.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b6f21",
   "metadata": {},
   "source": [
    "## 2.  Importar pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce0eba9",
   "metadata": {},
   "source": [
    "Apache Spark es una plataforma de computación distribuida de código abierto, algunas de las ventajas que justifican su uso son:\n",
    "* Velocidad en materia de aprendizaje automático: permite a los programadores realizar operaciones sobre un gran volumen de datos en clústeres de forma rápida y con tolerancia a fallos\n",
    "* Distintas plataformas para gestionar y procesar datos, como Spark SQL, Spark Streaming, Mlib o Graph X.\n",
    "<img src=\"imagenes\\pyspark2.png\" width=\"600\" height=\"300\" align=\"center \">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d388a",
   "metadata": {},
   "source": [
    "### 2.1 Preparación de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ed02a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfac763f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass         int64\n",
       "LotFrontage      float64\n",
       "LotArea            int64\n",
       "Neighborhood       int64\n",
       "OverallQual        int64\n",
       "OverallCond        int64\n",
       "MasVnrArea       float64\n",
       "BsmtFinSF1       float64\n",
       "BsmtFinSF2       float64\n",
       "BsmtUnfSF        float64\n",
       "LowQualFinSF       int64\n",
       "BsmtFullBath     float64\n",
       "BsmtHalfBath     float64\n",
       "BedroomAbvGr       int64\n",
       "KitchenAbvGr       int64\n",
       "TotRmsAbvGrd       int64\n",
       "Fireplaces         int64\n",
       "GarageYrBlt      float64\n",
       "GarageCars       float64\n",
       "WoodDeckSF         int64\n",
       "OpenPorchSF        int64\n",
       "EnclosedPorch      int64\n",
       "3SsnPorch          int64\n",
       "ScreenPorch        int64\n",
       "PoolArea           int64\n",
       "MiscVal            int64\n",
       "MoSold             int64\n",
       "YrSold             int64\n",
       "TotalArea        float64\n",
       "Bathrooms        float64\n",
       "YearAverage      float64\n",
       "PrecioVenta      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "739f1b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>TotalArea</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>YearAverage</th>\n",
       "      <th>PrecioVenta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>4824.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>4246.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2001.5</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>4832.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1942.5</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>6377.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  Neighborhood  OverallQual  OverallCond  \\\n",
       "0          60         65.0     8450             1            7            5   \n",
       "1          20         80.0     9600             2            6            8   \n",
       "2          60         68.0    11250             1            7            5   \n",
       "3          70         60.0     9550             3            7            5   \n",
       "4          60         84.0    14260             4            8            5   \n",
       "\n",
       "   MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  3SsnPorch  ScreenPorch  \\\n",
       "0       196.0       706.0         0.0      150.0  ...          0            0   \n",
       "1         0.0       978.0         0.0      284.0  ...          0            0   \n",
       "2       162.0       486.0         0.0      434.0  ...          0            0   \n",
       "3         0.0       216.0         0.0      540.0  ...          0            0   \n",
       "4       350.0       655.0         0.0      490.0  ...          0            0   \n",
       "\n",
       "   PoolArea  MiscVal  MoSold  YrSold  TotalArea  Bathrooms  YearAverage  \\\n",
       "0         0        0       2    2008     4824.0        2.5       2003.0   \n",
       "1         0        0       5    2007     4246.0        2.0       1976.0   \n",
       "2         0        0       9    2008     5100.0        2.5       2001.5   \n",
       "3         0        0       2    2006     4832.0        1.0       1942.5   \n",
       "4         0        0      12    2008     6377.0        2.5       2000.0   \n",
       "\n",
       "   PrecioVenta  \n",
       "0     208500.0  \n",
       "1     181500.0  \n",
       "2     223500.0  \n",
       "3     140000.0  \n",
       "4     250000.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6ec00",
   "metadata": {},
   "source": [
    "A continuación creamos un label personalizado con los tipos asignados manualmente y con los campos de tipo object excluidos salvo la variable barrio la cual ha sido discretizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d980a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    ('TipoDeVienda', typ.IntegerType()),\n",
    "    ('LongitudDeLaCalle', typ.FloatType()),\n",
    "    ('AreaDelTerreno', typ.IntegerType()),\n",
    "    ('Barrio', typ.IntegerType()),\n",
    "    ('CalidadDeLaVivienda', typ.IntegerType()),\n",
    "    \n",
    "    ('CondicionesDeLaVivienda', typ.IntegerType()),\n",
    "    ('PiesCuadradosDeFachada', typ.FloatType()),\n",
    "    ('PiesCuadradosDeSotanoTerminados', typ.FloatType()),\n",
    "    ('PiesCuadradosDeSotano2Terminados', typ.FloatType()),\n",
    "    ('PiesCuadradosDeSotanoNoTerminados', typ.FloatType()),\n",
    "    \n",
    "    ('PiesCuadradosDeBajaCalidad', typ.IntegerType()),\n",
    "    ('BaniosEnterosEnSotano', typ.FloatType()),\n",
    "    ('BaniosPequeniosEnSotano', typ.FloatType()),\n",
    "    ('DormitoriosSobreSuelo', typ.IntegerType()),\n",
    "    ('CocinasSobresSuelo', typ.IntegerType()),\n",
    "    \n",
    "    ('habitacionesSobreSueloNoBanios', typ.IntegerType()),\n",
    "    ('Chimeneas', typ.IntegerType()),\n",
    "    ('AnioDeConstruccionDelGaraje', typ.FloatType()),\n",
    "    ('CochesDelGaraje', typ.FloatType()),\n",
    "    ('PiesCuadradosDeTerrazaDeMaderaSobreSuelo', typ.IntegerType()),\n",
    "    \n",
    "    ('PiesCuadradosDePorcheAbierto', typ.IntegerType()),\n",
    "    ('PiesCuadradosDePorcheCerrado', typ.IntegerType()),\n",
    "    ('PorcheThreeSeasson', typ.IntegerType()),\n",
    "    ('PorcheAcristalado', typ.IntegerType()),\n",
    "    ('AreaDePiscina', typ.IntegerType()),\n",
    "    \n",
    "    ('PrecioDeLosMiscelaneos', typ.IntegerType()),\n",
    "    ('MesDeVenta', typ.IntegerType()),\n",
    "    ('AnioDeVenta', typ.IntegerType()),\n",
    "    ('AreaHabitableTotal', typ.FloatType()),\n",
    "    ('Banios', typ.FloatType()),\n",
    "    \n",
    "    ('EdadMediaCasa', typ.FloatType()),\n",
    "    ('PrecioDeLaVivenda', typ.FloatType())\n",
    "]\n",
    "\n",
    "\n",
    "schema = typ.StructType([\n",
    "    typ.StructField(e[0], e[1], False) for e in labels\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10726941",
   "metadata": {},
   "source": [
    "### 2.2 SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4befa004",
   "metadata": {},
   "source": [
    "Inicializamos la sesión en spark, este es el punto de entrada a todas las funciones de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af5cb06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MSI:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cbee2e",
   "metadata": {},
   "source": [
    "Spark SQL es un módulo de Apache Spark para el procesamiento de datos estructurados. \n",
    "A diferencia de Spark API RDD, sus interfaces proporcionan información adicional (puesto que reciben información sobre la estructura de los datos), lo cual aplica a más funcionalidades.\n",
    "\n",
    "La mayor abstracción en la API de Spark SQL es el DataFrame, el cual conserva caracerísticas de los RDDs: inmutabilidad, resiliencia y computación distribuida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34f78a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc) \n",
    "#SQLContext permite conectar el motor con diferentes fuentes de datos. Se utiliza para iniciar las funcionalidades de Spark SQL\n",
    "\n",
    "spark.createDataFrame(vars_train)\n",
    "vars_train = sqlContext.createDataFrame(vars_train,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35243479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+--------------+------+-------------------+-----------------------+----------------------+-------------------------------+--------------------------------+---------------------------------+--------------------------+---------------------+-----------------------+---------------------+------------------+------------------------------+---------+---------------------------+---------------+----------------------------------------+----------------------------+----------------------------+------------------+-----------------+-------------+----------------------+----------+-----------+------------------+------+-------------+-----------------+\n",
      "|TipoDeVienda|LongitudDeLaCalle|AreaDelTerreno|Barrio|CalidadDeLaVivienda|CondicionesDeLaVivienda|PiesCuadradosDeFachada|PiesCuadradosDeSotanoTerminados|PiesCuadradosDeSotano2Terminados|PiesCuadradosDeSotanoNoTerminados|PiesCuadradosDeBajaCalidad|BaniosEnterosEnSotano|BaniosPequeniosEnSotano|DormitoriosSobreSuelo|CocinasSobresSuelo|habitacionesSobreSueloNoBanios|Chimeneas|AnioDeConstruccionDelGaraje|CochesDelGaraje|PiesCuadradosDeTerrazaDeMaderaSobreSuelo|PiesCuadradosDePorcheAbierto|PiesCuadradosDePorcheCerrado|PorcheThreeSeasson|PorcheAcristalado|AreaDePiscina|PrecioDeLosMiscelaneos|MesDeVenta|AnioDeVenta|AreaHabitableTotal|Banios|EdadMediaCasa|PrecioDeLaVivenda|\n",
      "+------------+-----------------+--------------+------+-------------------+-----------------------+----------------------+-------------------------------+--------------------------------+---------------------------------+--------------------------+---------------------+-----------------------+---------------------+------------------+------------------------------+---------+---------------------------+---------------+----------------------------------------+----------------------------+----------------------------+------------------+-----------------+-------------+----------------------+----------+-----------+------------------+------+-------------+-----------------+\n",
      "|          60|             65.0|          8450|     1|                  7|                      5|                 196.0|                          706.0|                             0.0|                            150.0|                         0|                  1.0|                    0.0|                    3|                 1|                             8|        0|                     2003.0|            2.0|                                       0|                          61|                           0|                 0|                0|            0|                     0|         2|       2008|            4824.0|   2.5|       2003.0|         208500.0|\n",
      "+------------+-----------------+--------------+------+-------------------+-----------------------+----------------------+-------------------------------+--------------------------------+---------------------------------+--------------------------+---------------------+-----------------------+---------------------+------------------+------------------------------+---------+---------------------------+---------------+----------------------------------------+----------------------------+----------------------------+------------------+-----------------+-------------+----------------------+----------+-----------+------------------+------+-------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vars_train.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e337d7",
   "metadata": {},
   "source": [
    "## 3. Estimador y modelos sin mejoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a13b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos el dataset en train y test (70 y 30 respectivamente)\n",
    "(trainingData, testData) = vars_train.randomSplit([0.7, 0.3], seed=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9f64c",
   "metadata": {},
   "source": [
    "### 3.1 Vector assembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edce9f",
   "metadata": {},
   "source": [
    "VectorAssembler es un transformador que convierte datos de varias columnas en una columna vectorial de una sola columna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47557e5",
   "metadata": {},
   "source": [
    "Buscamos todas las columnas del dataset que no sean el label (precio de vivienda).\n",
    "Lo realizamos mediante un select, con esto hacemos más preciso al modelo a la hora de añadir nuevas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2559057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature as ft\n",
    "featureCreator = ft.VectorAssembler(\n",
    "    inputCols=[col for col in vars_train.select(\"*\").columns if col!='PrecioDeLaVivenda'], #todas menos el target \n",
    "    outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d0e37e",
   "metadata": {},
   "source": [
    "### 3.2 Modelos de regresión "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457a8c4",
   "metadata": {},
   "source": [
    "Realizamos el modelo con un Random Forest y un Gradient Boosting para ver cual devuelve un menor RMSE (Raíz del MSE), y por lo tanto un mejor rendimiento de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad443c0a",
   "metadata": {},
   "source": [
    "* ### 3.2.1 Random Forest sin mejoras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e421a",
   "metadata": {},
   "source": [
    "El Random Forest es un modelo formado por muchos árboles de decisión. De manera que el resultado devuelto es obtenido tras promediar las predicciones de los árboles.\n",
    "\n",
    "Dichos árboles utilizan muestreos aleatorios del train durante el entrenamiento y están formados por subconjuntos aleatorios de características consideradas al dividir nodos. La clave es la baja correlación entre los modelos (árboles).\n",
    "\n",
    "Los motivos por los que hemos seleccionado este modelo como el primero a implementar son los siguientes:\n",
    "* Requiere muy pocas suposiciones, por lo que la preparación de los datos es mucho más leve en comparación con otros algoritmos; por ejemplo: no necesita estandarización.\n",
    "* Poco afectadas por valores atípicos al ponderar con medias o modas en la resolución.\n",
    "* Tiene un método efectivo para estimar datos faltantes; además predice bien para grandes cantidades de datos al utilizar varios árboles y reducir el riesgo de overfiting.\n",
    "<img src=\"imagenes\\randomforest.png\" width=\"700\" height=\"1000\" align=\"center \">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a2b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba5fbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo de random forest en este caso solo hace falta especificar el label\n",
    "rf = RandomForestRegressor(labelCol='PrecioDeLaVivenda')\n",
    "#el pipeline es un camino que indica los pasos que tiene que hacer el modelo en este caso\n",
    "#crea una columna vector que agrupa el resto de columnas y efectúa el random forest\n",
    "pipeline = Pipeline(stages=[featureCreator,rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5a6cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guarda el modelo entrenado con los datos de training en pModel\n",
    "pModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bd96467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guarda el test en pTest\n",
    "pTest = pModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbbbe640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se tiene que crear un evaluador de regresión para usarlo después\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    #la métrica que sale de este evaluador es la raiz cuadrada del error cuadrático medio(rsme),\n",
    "    #osea el error medio\n",
    "    labelCol=\"PrecioDeLaVivenda\", predictionCol=\"prediction\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8abf7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadratico medio random forest (RMSE) = 47379\n"
     ]
    }
   ],
   "source": [
    "#Con este código se imprime el valor de la raiz cuadrada del error cuadrático medio\n",
    "rmse = evaluator.evaluate(pTest)\n",
    "print(\"Error cuadratico medio Random Forest (RMSE) = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db6221",
   "metadata": {},
   "source": [
    "Obteniendo un RMSE de menor de 50.000 dólares, nos indica que, en promedio, nuestro modelo ha obtenido resultados que difieren en esa cifra de dólares del precio real. \n",
    "\n",
    "Hay que tener en cuenta que estas medidas provienen del promedio de las realizaciones de la prueba. Esto implica que cuando predecimos resultados sesgados (precios, ingresos, etc) lo más probable es que el error también sea sesgado.\n",
    "Esto puede ser debido a que en la mayoría de los casos el error es muy pequeño, pero que existen ejemplos con errores extremadamente grandes. Un error demasiado sesgado puede invalidar el resultado del promedio.\n",
    "\n",
    "Por otro lado, cuanto mayor es el precio de venta, menor significación tienen 50.000 dólares de diferencia; y viceversa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230cc458",
   "metadata": {},
   "source": [
    "* ### 3.2.2 Gradient Boosting sin mejoras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d222ab",
   "metadata": {},
   "source": [
    "Gradient Boosting es una familia de algoritmos basados en la secuencia de modelos predictivos débiles que en nuestro caso serán los árboles de decisión. La generación de dichos árboles se crea de forma que cada uno corrija los errores del anterior. Estos \"weak lerners\" suelen ser árboles poco profundos con no más de 3 o 4 niveles de profundidad. \n",
    "\n",
    "La razón por la que queremos comparar su resultado con el del Random Forest es debido a que, pese a tener características ventajosas muy similares que se adaptan a las del problema, iteran disminuyendo su error con enfoques distintos: \n",
    "El Gradient Boosting utiliza árboles débiles (alto sesgo, baja variación), por lo que el algoritmo se limita principalmente a reducir el sesgo. Por otro lado, los diversos árboles completamente desarrollados del RF (bajo sesgo, alta varianza); por lo que procuran reducir el error de la forma contraria: reduciendo la varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3cc2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "#lo mismo pero con otro tipo de modelo\n",
    "gbt = GBTRegressor(featuresCol=\"features\",labelCol='PrecioDeLaVivenda')#, maxIter=10)\n",
    "pipeline = Pipeline(stages=[featureCreator,gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e42fcf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e6a4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtTest = gbtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d00de82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadratico medio gradient boosting (RMSE) = 50820.9\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(gbtTest)\n",
    "print(\"Error cuadratico medio gradient boosting (RMSE) = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0919e",
   "metadata": {},
   "source": [
    "Random Forest devuelve resultados ligeramente mejores en el RMSE, por lo que será el modelo elegido para la optimización. Además, es mucho más fácil de sintonizar que GBM. Por lo general, hay dos hiperparámetros en RF: número de árboles y número de campos que se utilizarán para entrenar cada nodo. Aunque, por otro lado, está demostrado que GBM suele funcionar mejor que RF si los parámetros se ajustan con cuidado.\n",
    "\n",
    "La realidad es que los resultados son destacablemente similares precisamente debido a que ambos modelos trabajan sobre árboles de decisión, diferenciandose en el orden y la forma en el que estos se combinan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deabd41",
   "metadata": {},
   "source": [
    "## 4. Ajuste del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4556e2",
   "metadata": {},
   "source": [
    "### 4.1 Discretización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9915d",
   "metadata": {},
   "source": [
    "Discretizar una variable significa convertir un grupo de valores continuos en una segmentación discreta (mediante intervalos). Precisamente el RF puede beneficiarse de esta conversión puesto que utiliza la minimización de la entropía de la información heurística para seleccionar puntos de corte.\n",
    "\n",
    "\n",
    "Hemos seleccionado la variable \"PiesCuadradosDeFachada\" puesto que es una de las más correlacionadas con el precio de venta de la vivienda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9285c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature as ft\n",
    "\n",
    "discretizer = ft.QuantileDiscretizer(\n",
    "    numBuckets=20, \n",
    "    inputCol='PiesCuadradosDeFachada', \n",
    "    outputCol='PiesCuadradosDeFachada_discretized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719494e7",
   "metadata": {},
   "source": [
    "### 4.2 Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2fb00",
   "metadata": {},
   "source": [
    "Normalizar significa tipificar las escalas de las variables en una sola escala común, es decir: extender o comprimir valores de la variable en un rango definido; con la intención de evitar así relaciones y dependencias no deseadas entre datos. Suele ser utilizada previamente a una realización de promedios\n",
    "\n",
    "\n",
    "Random Forest presenta un carácter invariante a transformaciones de características individuales debido a que los campos no son comparados en magnitud con otros, sino en los rangos de una característica segmentada por el modelo. No obstante procederemos a la normalizacion del modelo siguiendo las instrucciones generales del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5668275",
   "metadata": {},
   "source": [
    "#### 4.2.1 Normalización 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dad26a",
   "metadata": {},
   "source": [
    "En primer lugar vamos a normalizar mediante el Standard Scaler, dicho algoritmo elimina la media y escala la varianza de la unidad utilizando estadísticos de la muestra de entrenamiento. La \"unidad estándar\" se calcula con la desviación estándar de la muestra corregida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96bb6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos la función ya parametrizada \n",
    "normalizer_features = ft.StandardScaler(\n",
    "    inputCol='features', \n",
    "    outputCol='normalized_features', \n",
    "    withMean=True, #Obtiene el valor de withMean o su valor predeterminado.\n",
    "    withStd=True  #Obtiene el valor de withStd o su valor predeterminado.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "242ce310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#especificamos que las features son las normalizadas\n",
    "rf = RandomForestRegressor(featuresCol='normalized_features',labelCol='PrecioDeLaVivenda')\n",
    "# también adaptamos el vector asembler para que no pase por el input los piescuadradosdefachada porque ha sido discretizada\n",
    "featureCreator_no_dis = ft.VectorAssembler(\n",
    "    inputCols=[col for col in vars_train.select(\"*\").columns if col!='PrecioDeLaVivenda' and col!='PiesCuadradosDeFachada]'], #todas menos el target \n",
    "    outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f74068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[discretizer,featureCreator_no_dis,normalizer_features,rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32fe1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78c1451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "795b058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadratico medio (RMSE) = 47379\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(test)\n",
    "print(\"Error cuadratico medio (RMSE) = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d444d",
   "metadata": {},
   "source": [
    "El RMSE no se reduce con este tipo de normalización en Random Forest debido a que altera la escala de las variables, no la segmentación de rangos; por lo que no ofrece ninguna mejoría"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b0863",
   "metadata": {},
   "source": [
    "#### 4.2.2 Normalización 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaa658b",
   "metadata": {},
   "source": [
    "MinMaxScaler modifica la escala de cada variable a un rango común (mínimo, máximo) mediante estadísticos muestrales. Es común la práctica de normalizar en un rango (0,1), que son los límites por defecto.\n",
    "\n",
    "A priori parece que, a diferencia de StandardScaler, sí podría variar el RMSE; debido a que podríamos alterar las particiones de los árboles de decisión. Aunque no esperamos grandes resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ce67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer_features_MMS=ft.MinMaxScaler(\n",
    "    inputCol='features', \n",
    "    outputCol='normalized_features', \n",
    "    #withMean=True,\n",
    "    #withStd=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b553b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[discretizer,featureCreator_no_dis,normalizer_features_MMS,rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(test)\n",
    "print(\"Error cuadratico medio (RMSE) = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692ba1a",
   "metadata": {},
   "source": [
    "Baja levemente el promedio del error, simplemente ha variado ligeramente las particiones de algunas variables dentro de ciertos árboles de decisión. Por lo que parece que nuestra hipótesis previa estaba bien encaminada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa4cf7",
   "metadata": {},
   "source": [
    "### 4.3 Hypertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab2c8b",
   "metadata": {},
   "source": [
    "A diferencia de los parámetros del modelo, los cuales se aprenden durante el entrenamiento, los hiperparámetros deben establecerse antes del entrenamiento. En el caso del Random Forest, los hiperparámetros son el número de árboles de decisión y el número de características que evaluará cada árbol. \n",
    "\n",
    "Cada paradigma funciona mejor con unos u otros hiperparámetros; la tarea del científico de datos es encontrar la combinación que mejor aproxime las soluciones reales del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e83b148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.tuning as tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d87ea37",
   "metadata": {},
   "source": [
    "#### 4.3.1 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb2b5f",
   "metadata": {},
   "source": [
    "Creamos varios modelos combinando hiperparámetros a través de pipelines. En total se crearán 9 modelos 3*3.\n",
    "\n",
    "La finalidad es encontrar la mejor combinación de los nueve modelos probados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ccd63dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[discretizer,featureCreator,normalizer_features,rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88dfd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = tune.ParamGridBuilder().addGrid(rf.numTrees, [20,25,30]).addGrid(rf.maxDepth, [5,6,9]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114b62e",
   "metadata": {},
   "source": [
    "Hay que poner un número reducido de valores porque muchos modelos sobrecargarían el ordenador; se suelen usar 3x3 o 10x10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dac154",
   "metadata": {},
   "source": [
    "#### 4.3.2 Validación Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b8daf9",
   "metadata": {},
   "source": [
    "CrossValidator divide el conjunto de datos en \"pliegues\" o conjuntos de datos separados: prueba y entrenamiento. Habiendo que establecer mediante parámetro el número de pliegues que se deseen realizar. \n",
    "\n",
    "Por ejemplo: numFolds=3; generaríamos 3 pares datasets (train 70% y test 30%). Para evaluar calcularíamos el RMSE de los 3 pliegues, ajustando los 3 pares de conjuntos diferentes\n",
    "\n",
    "\n",
    "Esta técnica tiene un alto coste computacional; sin embargo, también es un método estadísticamente más sólido que el ajuste manual heurístico a la hora de seleccionar los hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "973fa7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = tune.CrossValidator(estimator=pipeline,estimatorParamMaps=grid,evaluator=evaluator,numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8d7d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "727de488",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f7b85f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadratico medio (RMSE) sin hypertuning en los datos test = 47379\n",
      "Error cuadratico medio (RMSE) con hypertuning en los datos test = 46735.2\n"
     ]
    }
   ],
   "source": [
    "#comparación de errores\n",
    "rmse = evaluator.evaluate(test)\n",
    "print(\"Error cuadratico medio (RMSE) sin hypertuning en los datos test = %g\" % rmse)\n",
    "rmse = evaluator.evaluate(results)\n",
    "print(\"Error cuadratico medio (RMSE) con hypertuning en los datos test = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ec3a88",
   "metadata": {},
   "source": [
    "El RMSE del modelo se reduce aproximadamente en unos 5.000 dólares, lo cual es una mejora considerable de la predicción del modelo. \n",
    "\n",
    "Esto se debe a que se ha garantizado la independiencia de la partición entre datos de entrenamiento y prueba. Y a que se han optimizado los hiperparámetros del modelo, seleccionando los que se ajustan la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a47ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e68f1cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor número de árboles es: 30\n",
      "El mejor valor de profundidad es: 6\n"
     ]
    }
   ],
   "source": [
    "#código que me imprime que hyperparámetros son los mejores para el modelo\n",
    "print('El mejor número de árboles es: {}'.format(bestModel.stages[-1]._java_obj.getNumTrees()))\n",
    "print('El mejor valor de profundidad es: {}'.format(bestModel.stages[-1]._java_obj.getMaxDepth()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e44bf9",
   "metadata": {},
   "source": [
    "El mejor modelo devuelto por el grid consta de los siguientes hiperparámetros:\n",
    "* Número de árboles: 30\n",
    "* Profundidad de árbol: 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58108d60",
   "metadata": {},
   "source": [
    "#### 4.3.3 Selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b8f75",
   "metadata": {},
   "source": [
    "La selección de características indentifica las características más influyentes durante el entrenamiento del modelo. Reduciendo el tamaño del espacio de funciones podemos mejorar el rendimiento del aprendizaje estadístico, además de su velocidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "#me selecciona que variables son las más relevantes para el modelo\n",
    "selector = ChiSqSelector(numTopFeatures=6, featuresCol=\"features\",\n",
    "                         outputCol=\"selectedFeatures\", labelCol=\"PrecioDeLaVivenda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b8856d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actualizo el normalizer porque ahora el input es diferente y quiero que funcione bien\n",
    "normalizer_features_selected_features = ft.StandardScaler(\n",
    "    inputCol='selectedFeatures', \n",
    "    outputCol='normalized_features', \n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "209caca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[discretizer,featureCreator,selector,normalizer_features_selected_features,rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75131920",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c691772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sTest = sModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e06f2d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadratico medio (RMSE) sin reducir variables = 47379\n",
      "Error cuadratico medio (RMSE) reduciendo variables = 50980.8\n"
     ]
    }
   ],
   "source": [
    "#comparativa de errores\n",
    "rmse = evaluator.evaluate(test)\n",
    "print(\"Error cuadratico medio (RMSE) sin reducir variables = %g\" % rmse)\n",
    "rmse = evaluator.evaluate(sTest)\n",
    "print(\"Error cuadratico medio (RMSE) reduciendo variables = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d29832",
   "metadata": {},
   "source": [
    "Ha subido el error, esto puede ser debido a dos motivos:\n",
    "* Reducir demasiado el número de variables, de manera que acabamos perdiendo información.\n",
    "* En teoría ChiSqSelector se utiliza para etiquetas categóricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1184f87",
   "metadata": {},
   "source": [
    "#### 4.3.4  Redución de dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7cc6f0",
   "metadata": {},
   "source": [
    "La reducción de dimensionalidad trata de reducir el número de variables consideradas en el modelo. Su funcionalidad radica en:\n",
    "* Eliminación de la característica: eliminación de variables redundantes o que no proporcionan suficiente información.\n",
    "* Extracción de variables: formar nuevas variables a partir de las antiguas\n",
    "\n",
    "El análisis de componentes principales (PCA) consiste precisamente en la extracción de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d3986d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0fb0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol='pca_features',labelCol='PrecioDeLaVivenda',)\n",
    "#código para la reducción de dimensionalidad\n",
    "pca = PCA(k=9, inputCol=\"features\", outputCol=\"pca_features\")\n",
    "pipeline = Pipeline(stages=[featureCreator,pca,rf])\n",
    "modelPCA = pipeline.fit(trainingData)\n",
    "testPCA=modelPCA.transform(testData)#.collect()[0].pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1805e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadratico medio (RMSE) sin  pca = 47379\n",
      "Error cuadratico medio (RMSE) con pca = 49353.3\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(test)\n",
    "print(\"Error cuadratico medio (RMSE) sin  pca = %g\" % rmse)\n",
    "rmse = evaluator.evaluate(testPCA)\n",
    "print(\"Error cuadratico medio (RMSE) con pca = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad948e",
   "metadata": {},
   "source": [
    "El error ha aumentado ligeramente, probablemente sea por comprimir demasiado las variables al reducir la dimensionalidad a 9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
